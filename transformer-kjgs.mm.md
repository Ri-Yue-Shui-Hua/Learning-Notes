
# transformer
## 1. 视觉Transformer基础
### 1. Self-attention
### 2. transformer
- NIPS 2017
- Google Research,Brain Team

### 3. DETR
- ECCV2020
- FaceBook AI

## 2. 视觉Transformer进阶
### 4. Deformable DETR
- ICLR2021
- 商汤代季峰老师组

### 5. ViT(Vision Transformer)
- ICLR2021
- Google Research, Brain Teeam
- 
### 6. IPT
- 北京华为诺亚方舟实验室

## 3. Transformer在识别任务的演进
### 7. DeiT
- FaceBook AI
### 8. Visual Transformer
- UC Berkeley

## 4. Transformer内部机制的探究

### 9. TNT(Transformer in Transformer)
- 北京华为诺亚方舟实验室
### 10. CPVT
- ICLR 2023
- 美团

## 5. 轻量化Transformer (1)
### 11. HAT
- ACL 2020
- MIT 韩松团队

### 12. Lite-Transformer
- ICLR 2020
- MIT 韩松团队

## 6. 将卷积融入视觉 Transformer (1)

### 13. CvT
- 麦吉尔大学, 微软云+AI

### 14. CeiT
- 商汤

## 7. 轻量化Transformer (2)

### 15. DeFINE
- ICLR 2020
- 华盛顿大学

### 16. DeLighT
- ICLR 2021
- Facebook AI

## 8. 更深的视觉 Transformer

### 17. DeepViT
- 新加坡国立大学, 字节跳动 AI Lab(美国)

### 18. CaiT
- Facebook

## 9. 更快更小的 Transformer

### 19. LeViT: 用于快速推理的视觉 Transformer
- Facebook，DeiT 一作 Hugo Touvron 挂名

### 20. ViT-Lite: 紧凑型视觉 Transformer，更小更简单
- 俄勒冈大学，UIUC，PAIR

## 10. 视觉 Transformer 训练方式的演进

### 21. LV-ViT: 56M 参数训练视觉 Transformer
- 新加坡国立大学，字节跳动

### 22. 通过抑制过度平滑来改进视觉 Transformer 训练
- Facebook

## 11. 轻量化 Transformer (3)

### 23. Reformer:高效处理长序列的 Transformer
- ICLR 2020
- UC Berkeley, Google Research

### 24. Linformer:低秩矩阵逼近实现新的 Self-Attention
- Facebook AI

## 12. Transformer+图像质量评价

### 25. IQT:基于 Transformer 的感知图像质量评价
- LG，NTIRE 2021冠军方案

### 26. TRIP:Transformer+图像质量评价：
- NORCE Norwegian Research Centre，深圳大

## 13. Transformer 的精炼和底层视觉任务新探索

### 27. low-level 多个任务榜首被占领，中科大等联合提出：Uformer
- 中科院，中科大，刘健庄老师团队

### 28. Refiner：改进视觉Transformer的自注意力
- 新加坡国立大学

## 14. 将卷积融入视觉 Transformer (2)
### 29. FAIR提出：Convolutional stem is all you need! 探究 ViT 优化不稳定的本质原因
- FAIR，RossGirshick等巨佬

### 30. 谷歌提出 CoAtNet：结合卷积和注意力 89.77% Accuracy！
- 谷歌大脑，Quoc V. Le团队

## 15. Transformer 在识别任务的改进
### 31. T2T-ViT：在 ImageNet 上从头训练视觉 Transformer
- 新加坡国立大学冯佳时团队，依图科技颜水成团队
### 32. VOLO 刷新 CV 多项记录，无需额外训练数据，首次在 ImageNet 上达到87.1%
- 新加坡国立大学冯佳时团队，依图科技颜水成团队

## 16. Vision Transformer + NAS

### 33. HR-NAS：使用轻量级 Transformer 的高效搜索高分辨率神经架构
- 香港大学、字节跳动和中国人民大学

### 34. AutoFormer：搜索用于视觉识别的 Transformer
- 微软

## 17. Swin Transformer：各项任务SOTA模型 (1)

### 35. Swin Transformer: 屠榜各大 CV 任务的视觉 Transformer模型
- 微软亚研院，中科大

### 36. SwinIR: 用于图像复原的 Swin Transformer
- ETH Zurich

## 18. Attention is not all you need
### 37. 只使用纯粹的注意力机制就够了吗
- 谷歌，EPFL

## 19. MetaTransformer：简单到尴尬的视觉模型

### 38. MetaTransformer：简单到尴尬的视觉模型
- Sea AI Lab，新加坡国立大学

## 20. Swin Transformer：各项任务SOTA模型 (2)
### 39. Swin Transformer v2: 扩展容量和分辨率
- 微软亚研院，中科大

## 21. Transformer 用于底层视觉任务的探索
### 40. EDT：用于底层视觉的高效图像处理 Transformer
- 港中文，思谋科技

## 22. Transformer内部机制的探究
### 41. Pyramid TNT
- 北京华为诺亚方舟实验室

## 23. 小数据集训练视觉 Transformer 模型
### 42. 仅用2040张图片训练出的视觉 Transformer 模型
- 南京大学

## 24. 极深的 Transformer 模型
### 43. 解决 Transformer 训练难题，1000层 Transformer 也能稳定训练
- 微软亚洲研究院

## 25. 面向 TensorRT 的视觉 Transformer
### 44. 面向 TensorRT 的视觉 Transformer
- 字节跳动

## 26. 关于视觉 Transformer 你应该知道的3件事
### 45. 关于视觉 Transformer 你应该知道的3件事
- Meta AI，DeiT 一作团队


## 27. 视觉 Transformer 的复仇：DeiT III
### 46. 视觉 Transformer 的复仇：DeiT III
- Meta AI，DeiT 一作团队

## 28. TinyViT：小型 ViT 的快速预训练蒸馏

### 47. TinyViT：小型 ViT 的快速预训练蒸馏
- 微软

## 29. MiniViT：通过权重复用压缩视觉 Transformer 模型

### 48. MiniViT：通过权重复用压缩视觉 Transformer 模型
- 微软

## 30. 无需微调加速大规模视觉 Transformer 密集预测任务的方法

### 49 无需微调加速大规模视觉 Transformer 密集预测任务的方法
- 微软亚洲研究院

## 31. 动态 Token 稀疏化实现高效的视觉 Transformer

### 50. DynamicViT：动态 Token 稀疏化实现高效的视觉 Transformer
- 清华大学，周杰，鲁继文团队，UCLA

## 32. 无需训练，Token 合并打造更快的 ViT 架构
### 51. 无需训练，Token 合并打造更快的 ViT 架构
- 佐治亚理工学院，Meta AI

## 33. 220亿参数的巨大视觉 Transformer
### 52. 扩展到220亿参数的巨大视觉 Transformer
- 谷歌，含 ViT 作者








